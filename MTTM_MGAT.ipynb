{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8c35098f-de26-4b08-b797-5be34b1d8fe1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/200], Loss: 0.6775\n",
      "Epoch [2/200], Loss: 0.6670\n",
      "Epoch [3/200], Loss: 0.6860\n",
      "Epoch [4/200], Loss: 0.6565\n",
      "Epoch [5/200], Loss: 0.6838\n",
      "Epoch [6/200], Loss: 0.5521\n",
      "Epoch [7/200], Loss: 0.5768\n",
      "Epoch [8/200], Loss: 0.3839\n",
      "Epoch [9/200], Loss: 0.4500\n",
      "Epoch [10/200], Loss: 0.4030\n",
      "Epoch [11/200], Loss: 0.4865\n",
      "Epoch [12/200], Loss: 0.4438\n",
      "Epoch [13/200], Loss: 0.5197\n",
      "Epoch [14/200], Loss: 0.3598\n",
      "Epoch [15/200], Loss: 0.5107\n",
      "Epoch [16/200], Loss: 0.4010\n",
      "Epoch [17/200], Loss: 0.3872\n",
      "Epoch [18/200], Loss: 0.3967\n",
      "Epoch [19/200], Loss: 0.3528\n",
      "Epoch [20/200], Loss: 0.3606\n",
      "Epoch [21/200], Loss: 0.3815\n",
      "Epoch [22/200], Loss: 0.4583\n",
      "Epoch [23/200], Loss: 0.3484\n",
      "Epoch [24/200], Loss: 0.3988\n",
      "Epoch [25/200], Loss: 0.3777\n",
      "Epoch [26/200], Loss: 0.4028\n",
      "Epoch [27/200], Loss: 0.5175\n",
      "Epoch [28/200], Loss: 0.3801\n",
      "Epoch [29/200], Loss: 0.4022\n",
      "Epoch [30/200], Loss: 0.3797\n",
      "Epoch [31/200], Loss: 0.3466\n",
      "Epoch [32/200], Loss: 0.3570\n",
      "Epoch [33/200], Loss: 0.4612\n",
      "Epoch [34/200], Loss: 0.3763\n",
      "Epoch [35/200], Loss: 0.4141\n",
      "Epoch [36/200], Loss: 0.3548\n",
      "Epoch [37/200], Loss: 0.3223\n",
      "Epoch [38/200], Loss: 0.4103\n",
      "Epoch [39/200], Loss: 0.4380\n",
      "Epoch [40/200], Loss: 0.3532\n",
      "Epoch [41/200], Loss: 0.4079\n",
      "Epoch [42/200], Loss: 0.3156\n",
      "Epoch [43/200], Loss: 0.4460\n",
      "Epoch [44/200], Loss: 0.3458\n",
      "Epoch [45/200], Loss: 0.3530\n",
      "Epoch [46/200], Loss: 0.3470\n",
      "Epoch [47/200], Loss: 0.3889\n",
      "Epoch [48/200], Loss: 0.3527\n",
      "Epoch [49/200], Loss: 0.3136\n",
      "Epoch [50/200], Loss: 0.4041\n",
      "Epoch [51/200], Loss: 0.3445\n",
      "Epoch [52/200], Loss: 0.3163\n",
      "Epoch [53/200], Loss: 0.3760\n",
      "Epoch [54/200], Loss: 0.4073\n",
      "Epoch [55/200], Loss: 0.3133\n",
      "Epoch [56/200], Loss: 0.3446\n",
      "Epoch [57/200], Loss: 0.4071\n",
      "Epoch [58/200], Loss: 0.3759\n",
      "Epoch [59/200], Loss: 0.3445\n",
      "Epoch [60/200], Loss: 0.3446\n",
      "Epoch [61/200], Loss: 0.3758\n",
      "Epoch [62/200], Loss: 0.3134\n",
      "Epoch [63/200], Loss: 0.3758\n",
      "Epoch [64/200], Loss: 0.4384\n",
      "Epoch [65/200], Loss: 0.3134\n",
      "Epoch [66/200], Loss: 0.3446\n",
      "Epoch [67/200], Loss: 0.3446\n",
      "Epoch [68/200], Loss: 0.3759\n",
      "Epoch [69/200], Loss: 0.4384\n",
      "Epoch [70/200], Loss: 0.3758\n",
      "Epoch [71/200], Loss: 0.3133\n",
      "Epoch [72/200], Loss: 0.3133\n",
      "Epoch [73/200], Loss: 0.3758\n",
      "Epoch [74/200], Loss: 0.3134\n",
      "Epoch [75/200], Loss: 0.3446\n",
      "Epoch [76/200], Loss: 0.4072\n",
      "Epoch [77/200], Loss: 0.3445\n",
      "Epoch [78/200], Loss: 0.3758\n",
      "Epoch [79/200], Loss: 0.3446\n",
      "Epoch [80/200], Loss: 0.4071\n",
      "Epoch [81/200], Loss: 0.3445\n",
      "Epoch [82/200], Loss: 0.3133\n",
      "Epoch [83/200], Loss: 0.3446\n",
      "Epoch [84/200], Loss: 0.3133\n",
      "Epoch [85/200], Loss: 0.4383\n",
      "Epoch [86/200], Loss: 0.3446\n",
      "Epoch [87/200], Loss: 0.3446\n",
      "Epoch [88/200], Loss: 0.3445\n",
      "Epoch [89/200], Loss: 0.3758\n",
      "Epoch [90/200], Loss: 0.3133\n",
      "Epoch [91/200], Loss: 0.3758\n",
      "Epoch [92/200], Loss: 0.3446\n",
      "Epoch [93/200], Loss: 0.3445\n",
      "Epoch [94/200], Loss: 0.3445\n",
      "Epoch [95/200], Loss: 0.3758\n",
      "Epoch [96/200], Loss: 0.3446\n",
      "Epoch [97/200], Loss: 0.3445\n",
      "Epoch [98/200], Loss: 0.3445\n",
      "Epoch [99/200], Loss: 0.4695\n",
      "Epoch [100/200], Loss: 0.3133\n",
      "Epoch [101/200], Loss: 0.3445\n",
      "Epoch [102/200], Loss: 0.3445\n",
      "Epoch [103/200], Loss: 0.3758\n",
      "Epoch [104/200], Loss: 0.3445\n",
      "Epoch [105/200], Loss: 0.3758\n",
      "Epoch [106/200], Loss: 0.3133\n",
      "Epoch [107/200], Loss: 0.3758\n",
      "Epoch [108/200], Loss: 0.3133\n",
      "Epoch [109/200], Loss: 0.3445\n",
      "Epoch [110/200], Loss: 0.3133\n",
      "Epoch [111/200], Loss: 0.3445\n",
      "Epoch [112/200], Loss: 0.4383\n",
      "Epoch [113/200], Loss: 0.3133\n",
      "Epoch [114/200], Loss: 0.3758\n",
      "Epoch [115/200], Loss: 0.3133\n",
      "Epoch [116/200], Loss: 0.3133\n",
      "Epoch [117/200], Loss: 0.3445\n",
      "Epoch [118/200], Loss: 0.3133\n",
      "Epoch [119/200], Loss: 0.3445\n",
      "Epoch [120/200], Loss: 0.3445\n",
      "Epoch [121/200], Loss: 0.3133\n",
      "Epoch [122/200], Loss: 0.3445\n",
      "Epoch [123/200], Loss: 0.3445\n",
      "Epoch [124/200], Loss: 0.3758\n",
      "Epoch [125/200], Loss: 0.3445\n",
      "Epoch [126/200], Loss: 0.3445\n",
      "Epoch [127/200], Loss: 0.3758\n",
      "Epoch [128/200], Loss: 0.3758\n",
      "Epoch [129/200], Loss: 0.3445\n",
      "Epoch [130/200], Loss: 0.3445\n",
      "Epoch [131/200], Loss: 0.3758\n",
      "Epoch [132/200], Loss: 0.3758\n",
      "Epoch [133/200], Loss: 0.3445\n",
      "Epoch [134/200], Loss: 0.3445\n",
      "Epoch [135/200], Loss: 0.3133\n",
      "Epoch [136/200], Loss: 0.4383\n",
      "Epoch [137/200], Loss: 0.3445\n",
      "Epoch [138/200], Loss: 0.3445\n",
      "Epoch [139/200], Loss: 0.3445\n",
      "Epoch [140/200], Loss: 0.3445\n",
      "Epoch [141/200], Loss: 0.4070\n",
      "Epoch [142/200], Loss: 0.3133\n",
      "Epoch [143/200], Loss: 0.4717\n",
      "Epoch [144/200], Loss: 0.6416\n",
      "Epoch [145/200], Loss: 0.7154\n",
      "Epoch [146/200], Loss: 0.6569\n",
      "Epoch [147/200], Loss: 0.6048\n",
      "Epoch [148/200], Loss: 0.6055\n",
      "Epoch [149/200], Loss: 0.5552\n",
      "Epoch [150/200], Loss: 0.6256\n",
      "Epoch [151/200], Loss: 0.6881\n",
      "Epoch [152/200], Loss: 0.5617\n",
      "Epoch [153/200], Loss: 0.6928\n",
      "Epoch [154/200], Loss: 0.5938\n",
      "Epoch [155/200], Loss: 0.6193\n",
      "Epoch [156/200], Loss: 0.8620\n",
      "Epoch [157/200], Loss: 0.6584\n",
      "Epoch [158/200], Loss: 0.5962\n",
      "Epoch [159/200], Loss: 0.5931\n",
      "Epoch [160/200], Loss: 0.5633\n",
      "Epoch [161/200], Loss: 0.6884\n",
      "Epoch [162/200], Loss: 0.6245\n",
      "Epoch [163/200], Loss: 0.7274\n",
      "Epoch [164/200], Loss: 0.4394\n",
      "Epoch [165/200], Loss: 0.6741\n",
      "Epoch [166/200], Loss: 0.5307\n",
      "Epoch [167/200], Loss: 0.6251\n",
      "Epoch [168/200], Loss: 0.6122\n",
      "Epoch [169/200], Loss: 0.5008\n",
      "Epoch [170/200], Loss: 0.5004\n",
      "Epoch [171/200], Loss: 0.6569\n",
      "Epoch [172/200], Loss: 0.5929\n",
      "Epoch [173/200], Loss: 0.6732\n",
      "Epoch [174/200], Loss: 0.5614\n",
      "Epoch [175/200], Loss: 0.5315\n",
      "Epoch [176/200], Loss: 0.5633\n",
      "Epoch [177/200], Loss: 0.5750\n",
      "Epoch [178/200], Loss: 0.6011\n",
      "Epoch [179/200], Loss: 0.4972\n",
      "Epoch [180/200], Loss: 0.7195\n",
      "Epoch [181/200], Loss: 0.4752\n",
      "Epoch [182/200], Loss: 0.6883\n",
      "Epoch [183/200], Loss: 0.6885\n",
      "Epoch [184/200], Loss: 0.4698\n",
      "Epoch [185/200], Loss: 0.4695\n",
      "Epoch [186/200], Loss: 0.5008\n",
      "Epoch [187/200], Loss: 0.4371\n",
      "Epoch [188/200], Loss: 0.5320\n",
      "Epoch [189/200], Loss: 0.7195\n",
      "Epoch [190/200], Loss: 0.6889\n",
      "Epoch [191/200], Loss: 0.4695\n",
      "Epoch [192/200], Loss: 0.6859\n",
      "Epoch [193/200], Loss: 0.5718\n",
      "Epoch [194/200], Loss: 0.8120\n",
      "Epoch [195/200], Loss: 0.4510\n",
      "Epoch [196/200], Loss: 0.5002\n",
      "Epoch [197/200], Loss: 0.7044\n",
      "Epoch [198/200], Loss: 0.5121\n",
      "Epoch [199/200], Loss: 0.5639\n",
      "Epoch [200/200], Loss: 0.5008\n",
      "Accuracy: 0.5200\n",
      "Precision: 0.4646\n",
      "Recall: 0.5169\n",
      "F1 Score: 0.4894\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import numpy as np\n",
    "\n",
    "# Parameters\n",
    "num_modalities = 3  # Images, text, and speech\n",
    "input_dim = 16  # Input feature dimension for each modality\n",
    "output_dim = 8  # Output dimension after attention layer\n",
    "batch_size = 32\n",
    "num_epochs = 200\n",
    "learning_rate = 0.01\n",
    "\n",
    "# Dummy Data Creation\n",
    "class MultimodalDummyDataset(Dataset):\n",
    "    def __init__(self, num_samples=1000):\n",
    "        self.num_samples = num_samples\n",
    "        self.image_data = torch.randn(num_samples, input_dim)  # Random image features\n",
    "        self.text_data = torch.randn(num_samples, input_dim)   # Random text features\n",
    "        self.speech_data = torch.randn(num_samples, input_dim) # Random speech features\n",
    "        self.labels = torch.randint(0, 2, (num_samples,))      # Random binary labels (0 or 1)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_samples\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            'image': self.image_data[idx],\n",
    "            'text': self.text_data[idx],\n",
    "            'speech': self.speech_data[idx],\n",
    "            'label': self.labels[idx]\n",
    "        }\n",
    "\n",
    "# Multimodal Graph Attention Layer\n",
    "class MultimodalGraphAttentionLayer(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(MultimodalGraphAttentionLayer, self).__init__()\n",
    "        self.attention_weights = nn.Parameter(torch.FloatTensor(input_dim, output_dim))\n",
    "        nn.init.xavier_uniform_(self.attention_weights)\n",
    "\n",
    "    def forward(self, x):\n",
    "        attention_scores = torch.matmul(x, self.attention_weights)\n",
    "        attention_weights = torch.softmax(attention_scores, dim=1)\n",
    "        return attention_weights * x\n",
    "\n",
    "# Multimodal Adversarial Neural Network\n",
    "# Multimodal Graph Attention Layer\n",
    "class MultimodalGraphAttentionLayer(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(MultimodalGraphAttentionLayer, self).__init__()\n",
    "        self.attention_weights = nn.Parameter(torch.FloatTensor(output_dim, output_dim))\n",
    "        self.linear_projection = nn.Linear(input_dim, output_dim)  # Project input to output_dim\n",
    "        nn.init.xavier_uniform_(self.attention_weights)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x_proj = self.linear_projection(x)  # Project input to output_dim\n",
    "        # Adjust the dimensions for matrix multiplication\n",
    "        attention_scores = torch.matmul(x_proj, self.attention_weights.t())  # Transpose weights\n",
    "        attention_weights = torch.softmax(attention_scores, dim=1)\n",
    "        return attention_weights * x_proj  # Multiply with projected input\n",
    "\n",
    "\n",
    "# Training and Evaluation\n",
    "train_dataset = MultimodalDummyDataset(num_samples=800)\n",
    "validate_dataset = MultimodalDummyDataset(num_samples=200)\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "validate_loader = DataLoader(dataset=validate_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "model = MultimodalAdversarialNN(input_dim, output_dim, num_modalities)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Training Loop\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    for batch in train_loader:\n",
    "        image = batch['image']\n",
    "        text = batch['text']\n",
    "        speech = batch['speech']\n",
    "        labels = batch['label']\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(image, text, speech)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}\")\n",
    "\n",
    "# Evaluation\n",
    "model.eval()\n",
    "y_true, y_pred = [], []\n",
    "with torch.no_grad():\n",
    "    for batch in validate_loader:\n",
    "        image = batch['image']\n",
    "        text = batch['text']\n",
    "        speech = batch['speech']\n",
    "        labels = batch['label']\n",
    "\n",
    "        outputs = model(image, text, speech)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "        y_true.extend(labels.numpy())\n",
    "        y_pred.extend(predicted.numpy())\n",
    "\n",
    "# Performance Metrics\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "precision = precision_score(y_true, y_pred)\n",
    "recall = recall_score(y_true, y_pred)\n",
    "f1 = f1_score(y_true, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4fc0493-94d6-41fb-8e7b-3e0e14154e28",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
